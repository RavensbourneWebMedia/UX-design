# Assessment criteria

Your final grade will be based on:

* [75% project](#project)
* [25% blog](#blog)


## Project


### Components

1. **Research** identifying problems and opportunities through [competitor analysis](sessions/session-02.md#competitor-analysis), examining audiences through [user interviews](sessions/session-03.md#user-interviews), understanding [behaviours](sessions/session-14.md#designing-behaviours) and interpreting your research data through [user personas](sessions/session-04.md#user-personas) 
* **Experimentation** exploring ideas through [wireframes](sessions/session-05.md#wireframing) and [user journeys](sessions/session-06.md#user-journeys), from paper to digital
* **Iteration** [prototyping](sessions/session-13.md#rapid-prototyping) and [user-testing](sessions/session-15.md#user-testing-preparation) your concepts (both [remotely](sessions/session-07.md#usability-testing) and [face2face](sessions/session-15.md#let-them-in-))
* **Communication** writing [motivational copy](sessions/session-10.md#your-turn) for [emails](sessions/session-11.md#engagement-email) and [Web interfaces](sessions/session-10.md#2-hack-your-interface-copy), formalising your project requirements through [user stories](sessions/session-13.md#your-stories), presenting both your project's output and process  


### Grades

#### F

[M.I.A.](http://en.wikipedia.org/wiki/Missing_in_action) We saw you around but you failed to show evidence of your work. 

#### E

* **Research** either your competitor analysis, user interviews or user personas are missing, or they are disconnected and disorganised 
* **Experimentation** you wireframed only a handful of screens using filler content (*Lorem ipsum*, no images); your user journeys are superficial and/or delusional (wishful, not based on research evidence) 
* **Iteration** your prototypes are hard to test and therefore your user-testing didn't provide useful insight; your process was erratic
* **Communication** your presentation(s) lacked clarity and completeness

#### D

* **Research** you dipped your toes into competitor analysis, user interviews and user personas but they are disconnected 
* **Experimentation** you wireframed a handful of screens using real(istic) content; your user journeys are based on research evidence but shallow (happy ending, no explanations) 
* **Iteration** you prototyped and user-tested one concept, however you haven't addressed the road bumps your users encountered (one iteration only)
* **Communication** your presentation(s) were complete

#### C

* **Research** whilst your competitor analysis, user interviews and user personas are decent, they could integrate better into your process 
* **Experimentation** you wireframed key screens using real(istic) content; your user journeys are based on research evidence and explore a few scenarios 
* **Iteration** you prototyped and user-tested a few concepts, tested them with several users and folded their feedback into your design process (at least two iterations)
* **Communication** your presentation(s) were clear and complete

#### B

* **Research** whilst your competitor analysis and user interviews are broad and integrated, they could be better documented; your user personas are good and varied (we don't need 7 photocopies of young professionals with disposable income and thirst for technology) 
* **Experimentation** you wireframed key screens using real(istic) content, and your user journeys explore several scenarios in depth; you explained how your design decisions are linked to research evidence
* **Iteration** you prototyped and user-tested several  concepts, tested them with users and folded their feedback into your design process; more than two iterations
* **Communication** your presentation(s) were clear, complete and engaging

#### A

* **Research** your competitor analysis is thorough, your user interviews insightful and well documented, your user personas go deeper and are varied. Your research provides a solid foundation for your design
* **Experimentation** you wireframed key screens using real(istic) content, experimenting with UI design patterns and explaining how your design decisions are linked to research evidence; your user journeys are based on research evidence, highlight pain points and offer branching solutions
* **Iteration** you prototyped and user-tested various  concepts, testing them both on a high level and refining the details (eg A/B testing); more than two iterations
* **Communication** your presentation(s) were clear, complete, engaging and original

## Blog

The blog should have at least 12 posts.

Topics from each week:

1. [What are my learning goals?](https://github.com/RavensbourneWebMedia/Blogging/blob/master/what-are-my-learning-goals.md)
* [Personifications](sessions/session-02.md#personifications)
* [User interviews](sessions/session-03.md#blog)
* [Make it like the PSD](sessions/session-05.md#blog)
* [The Internet's own boy](sessions/session-06.md#blog)
* [Remote user testing](sessions/session-07.md#blog)
* [The time is ripe for niche social networks](sessions/session-09.md#blog)
* [Exercises in style](session-10.md#test)
* [Your social network in 2 paragraphs](sessions/session-10.md#blog)
* [Interviewing humans](sessions/session-11.md#blog)
* [Issue map](sessions/session-12.md#blog)
* [Are UI walkthroughs evil?](sessions/session-13.md#blog)
* [Magical software](sessions/session-14.md#blog)
* [User-testing report](sessions/session-15.md#blog)
* [Invisible design](sessions/session-16.md#blog)
* [Transitional interfaces](sessions/session-17.md#blog)

Refer to the general **[Web Media blog assessment criteria](https://github.com/RavensbourneWebMedia/Blogging/blob/master/assessment-criteria.md)** for a detailed grading breakdown.